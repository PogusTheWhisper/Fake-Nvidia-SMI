{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install -Uq pip "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "teLBTKDXQM0M"
      },
      "outputs": [],
      "source": [
        "import datetime\n",
        "import random\n",
        "import string\n",
        "\n",
        "class FakeSMI:\n",
        "    def __init__(self):\n",
        "      pass\n",
        "\n",
        "    @staticmethod\n",
        "    def __date():\n",
        "      now = datetime.datetime.now()\n",
        "      current_time = now.strftime(\"%a %b %d %H:%M:%S %Y\")\n",
        "      print(current_time)\n",
        "\n",
        "    @staticmethod\n",
        "    def __header():\n",
        "      header = [\"+---------------------------------------------------------------------------------------+\",\n",
        "                \"| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\",\n",
        "                \"|-----------------------------------------+----------------------+----------------------+\",\n",
        "                \"| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\",\n",
        "                \"| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\",\n",
        "                \"|                                         |                      |               MIG M. |\",\n",
        "                \"|=========================================+======================+======================|\"]\n",
        "      for line in header:\n",
        "        print(line)\n",
        "\n",
        "    @staticmethod\n",
        "    def __footer():\n",
        "      footer = [\"+---------------------------------------------------------------------------------------+\",\n",
        "                \"| Processes:                                                                            |\",\n",
        "                \"|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\",\n",
        "                \"|        ID   ID                                                             Usage      |\",\n",
        "                \"|=======================================================================================|\",\n",
        "                \"|  No running processes found                                                           |\",\n",
        "                \"+---------------------------------------------------------------------------------------+\"]\n",
        "      for line in footer:\n",
        "        print(line)\n",
        "\n",
        "    @staticmethod\n",
        "    def __generate_serial():\n",
        "      while True:\n",
        "        serial = \"\".join(random.choices(string.ascii_uppercase + string.digits, k=2))\n",
        "        if not serial.isalpha():\n",
        "          return serial\n",
        "\n",
        "    def __h100(self, gpu_num):\n",
        "      for gpu_num in range(gpu_num):\n",
        "        serial = self.__generate_serial()\n",
        "        now_watt = random.randint(120, 130)\n",
        "        temp = random.randint(50, 55)\n",
        "        h100_status = [f\"|   {gpu_num}  NVIDIA H100 PCIe              Off  | 00000000:{serial}:00.0 Off |                    0 |\",\n",
        "                       f\"| N/A   {temp}C    P0             {now_watt}W / 500W |      0MiB / 40536MiB |      0%      Default |\",\n",
        "                        \"|                                         |                      |                  N/A |\",\n",
        "                        \"+-----------------------------------------+----------------------+----------------------+\"]\n",
        "        for line in h100_status:\n",
        "          print(line)\n",
        "\n",
        "    def __a100(self, gpu_num):\n",
        "      for gpu_num in range(gpu_num):\n",
        "        serial = self.__generate_serial()\n",
        "        now_watt = random.randint(40, 60)\n",
        "        temp = random.randint(30, 40)\n",
        "        a100_status = [f\"|   {gpu_num}  NVIDIA A100-SXM4-40GB         Off  | 00000000:{serial}:00.0 Off |                    0 |\",\n",
        "                       f\"| N/A   {temp}C    P0              {now_watt}W / 400W |      0MiB / 40536MiB |      0%      Default |\",\n",
        "                        \"|                                         |                      |                  N/A |\",\n",
        "                        \"+-----------------------------------------+----------------------+----------------------+\"]\n",
        "        for line in a100_status:\n",
        "          print(line)\n",
        "\n",
        "    def __v100(self, gpu_num):\n",
        "      for gpu_num in range(gpu_num):\n",
        "        serial = self.__generate_serial()\n",
        "        now_watt = random.randint(80, 90)\n",
        "        temp = random.randint(40, 45)\n",
        "        v100_status = [f\"|   {gpu_num}  V100-SXM4-16GB                Off  | 00000000:{serial}:00.0 Off |                    0 |\",\n",
        "                       f\"| N/A   {temp}C    P0              {now_watt}W / 300W |      0MiB / 16160MiB |      0%      Default |\",\n",
        "                        \"|                                         |                      |                  N/A |\",\n",
        "                        \"+-----------------------------------------+----------------------+----------------------+\"]\n",
        "        for line in v100_status:\n",
        "          print(line)\n",
        "\n",
        "    def __p100(self, gpu_num):\n",
        "      for gpu_num in range(gpu_num):\n",
        "        serial = self.__generate_serial()\n",
        "        now_watt = random.randint(60, 70)\n",
        "        temp = random.randint(35, 40)\n",
        "        p100_status = [f\"|   {gpu_num}  Tesla P100-PCIE-16GB          Off  | 00000000:{serial}:00.0 Off |                    0 |\",\n",
        "                       f\"| N/A   {temp}C    P0              {now_watt}W / 250W |      0MiB / 16280MiB |      0%      Default |\",\n",
        "                        \"|                                         |                      |                  N/A |\",\n",
        "                        \"+-----------------------------------------+----------------------+----------------------+\"]\n",
        "        for line in p100_status:\n",
        "          print(line)\n",
        "\n",
        "    def __k80(self, gpu_num):\n",
        "      for gpu_num in range(gpu_num):\n",
        "        serial = self.__generate_serial()\n",
        "        now_watt = random.randint(80, 99)\n",
        "        temp = random.randint(40, 50)\n",
        "        k80_status = [f\"|   {gpu_num}  Tesla K80                      Off | 00000000:{serial}:00.0 Off |                    0 |\",\n",
        "                      f\"| N/A   {temp}C    P0              {now_watt}W / 300W |      0MiB / 12288MiB |      0%      Default |\",\n",
        "                       \"|                                         |                      |                  N/A |\",\n",
        "                       \"+-----------------------------------------+----------------------+----------------------+\"]\n",
        "        for line in k80_status:\n",
        "          print(line)\n",
        "\n",
        "    def __t4(self, gpu_num):\n",
        "      for gpu_num in range(gpu_num):\n",
        "        serial = self.__generate_serial()\n",
        "        now_watt = random.randint(50, 60)\n",
        "        temp = random.randint(30, 35)\n",
        "        t4_status = [f\"|   {gpu_num}  Tesla T4                       Off | 00000000:{serial}:00.0 Off |                    0 |\",\n",
        "                     f\"| N/A   {temp}C    P0              {now_watt}W /  70W |      0MiB / 15109MiB |      0%      Default |\",\n",
        "                      \"|                                         |                      |                  N/A |\",\n",
        "                      \"+-----------------------------------------+----------------------+----------------------+\"]\n",
        "        for line in t4_status:\n",
        "          print(line)\n",
        "\n",
        "    def flex(self, gpu_type:str, gpu_num:int=1):\n",
        "      self.__date()\n",
        "      self.__header()\n",
        "      gpu_type=gpu_type.lower()\n",
        "\n",
        "      if gpu_type == 'h100':\n",
        "          self.__h100(gpu_num)\n",
        "\n",
        "      elif gpu_type == 'a100':\n",
        "          self.__a100(gpu_num)\n",
        "\n",
        "      elif gpu_type == 'v100':\n",
        "          self.__v100(gpu_num)\n",
        "\n",
        "      elif gpu_type == 'p100':\n",
        "        self.__p100(gpu_num)\n",
        "\n",
        "      elif gpu_type == 'k80':\n",
        "        self.__k80(gpu_num)\n",
        "\n",
        "      elif gpu_type == 't4':\n",
        "        self.__t4(gpu_num)\n",
        "      else:\n",
        "          print(f\"Invalid gpu_type: {gpu_type}\")\n",
        "\n",
        "      print(\"                                                                               \")\n",
        "      self.__footer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NK1YEMDtQtgY",
        "outputId": "4bc4998f-4b3b-4925-b5a2-993f50893364"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tue Apr 30 13:55:30 2024\n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  NVIDIA A100-SXM4-40GB         Off  | 00000000:D5:00.0 Off |                    0 |\n",
            "| N/A   34C    P0              57W / 400W |      0MiB / 40536MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "|   1  NVIDIA A100-SXM4-40GB         Off  | 00000000:3H:00.0 Off |                    0 |\n",
            "| N/A   36C    P0              41W / 400W |      0MiB / 40536MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "fake_smi_instance = FakeSMI()\n",
        "fake_smi_instance.flex('A100', 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TgLigsGQQhLc",
        "outputId": "9d542aa6-640c-4fb1-b953-5f56e0c1fe7b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mon Apr 29 15:13:50 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   38C    P8               9W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "ehix7z9HPXXe"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
